{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Scikit-Learn 完成預測\n",
    "### Scikit-Learn在三個面向提供支援。\n",
    "1. 獲取資料:***klearn.datasets***\n",
    "2. 掌握資料:***sklearn.preprocessing*** \n",
    "3. 機器學習:***sklearn Estimator API*** \n",
    "\n",
    "獲取資料的方式有很多種（包含檔案、資料庫、網路爬蟲、Kaggle Datasets等），<br>\n",
    "其中最簡單的方式是從Sklearn import 內建的資料庫。由於其特性隨手可得且不用下載，所以我們通常叫他**玩具資料**：\n",
    "\n",
    "# 基本架構\n",
    "\n",
    "* 讀取資料&pre-processing\n",
    "* 切分訓練集與測試集 \n",
    "* 模型配適\n",
    "* 預測 \n",
    "* 評估(計算成績可能是誤差值或正確率或..)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取Iris資料集與資料前處理\n",
    "\n",
    "Iris Flowers 資料集\n",
    "\n",
    "我們在這個項目中使用 Iris Data Set，這個資料集中的每個樣本有4個特徵，1個類別。該資料集1中的樣本類別數為3類，每類樣本數目為50個，總共150個樣本。\n",
    "\n",
    "屬性資訊：\n",
    "\n",
    "    花萼長度 sepal length(cm)\n",
    "    花萼寬度 sepal width(cm)\n",
    "    花瓣長度 petal length(cm)\n",
    "    花瓣寬度 petal width(cm)\n",
    "    類別：\n",
    "        Iris Setosa\n",
    "        Iris Versicolour\n",
    "        Iris Virginica\n",
    "\n",
    "樣本特徵資料是數值型的，而且單位都相同（釐米）。\n",
    "\n",
    "![Iris Flowers](iris_data.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)\n",
    "boston = datasets.load_boston()\n",
    "#print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target[:10]\n",
    "boston.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "X = iris.data[:, :2] # we only take the first two features. We could\n",
    "print(X.shape)\n",
    "Y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  \n",
       "5     18.7  394.12   5.21  \n",
       "6     15.2  395.60  12.43  \n",
       "7     15.2  396.90  19.15  \n",
       "8     15.2  386.63  29.93  \n",
       "9     15.2  386.71  17.10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#以下是組成 pandas DataFrame (也可以不用這種做)\n",
    "x = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "x.head(10)\n",
    "x = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "x.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "target_names: ['setosa' 'versicolor' 'virginica']\n",
      "6578\n",
      "boston target_names=?\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'MEDV'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bb8ad28a6b48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboston\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"boston target_names=?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"target_names: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboston\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MEDV'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'MEDV'"
     ]
    }
   ],
   "source": [
    "print(iris['data'].size)\n",
    "print(\"target_names: \"+str(iris['target_names']))\n",
    "print(boston['data'].size)\n",
    "print(\"boston target_names=?\")\n",
    "#print(\"target_names: \"+str(boston['MEDV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(iris['target'], columns=['target'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-cc0f7650aaf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miris_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sepal length (cm)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'petal length (cm)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0miris_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "iris_data = iris_data[['sepal length (cm)','petal length (cm)','target']]\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.concat([x,y], axis=0)\n",
    "iris_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  petal length (cm)  target\n",
       "0                5.1                1.4       0\n",
       "1                4.9                1.4       0\n",
       "2                4.7                1.3       0\n",
       "3                4.6                1.5       0\n",
       "4                5.0                1.4       0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = iris_data[iris_data['target'].isin([0,1])]\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切分訓練集與測試集\n",
    "> train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_data[['sepal length (cm)','petal length (cm)']], iris_data[['target']], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  petal length (cm)\n",
       "74                6.4                4.3\n",
       "24                4.8                1.9\n",
       "21                5.1                1.5\n",
       "33                5.5                1.4\n",
       "39                5.1                1.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  petal length (cm)\n",
       "87                6.3                4.4\n",
       "57                4.9                3.3\n",
       "80                5.5                3.8\n",
       "23                5.1                1.7\n",
       "18                5.7                1.7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization (z-score)\n",
    "    to compute the mean and standard deviation on a training set so as to be able to later reapply the same transformation on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_stats(dfs):\n",
    "    minimum = np.min(dfs)\n",
    "    maximum = np.max(dfs)\n",
    "    mu = np.mean(dfs)\n",
    "    sigma = np.std(dfs)\n",
    "    return (minimum, maximum, mu, sigma)\n",
    "\n",
    "\n",
    "def z_score(col, stats):\n",
    "    m, M, mu, s = stats\n",
    "    df = pd.DataFrame()\n",
    "    for c in col.columns:\n",
    "        df[c] = (col[c]-mu[c])/s[c]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.65697597,  1.07442806],\n",
       "       [-1.05620105, -0.61094929],\n",
       "       [-0.54748036, -0.89184551],\n",
       "       [ 0.13081389, -0.96206957],\n",
       "       [-0.54748036, -0.89184551]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = norm_stats(X_train)\n",
    "arr_x_train = np.array(z_score(X_train, stats))\n",
    "arr_y_train = np.array(y_train)\n",
    "arr_x_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.42285714 2.77      ]\n",
      "[0.58971456 1.42401344]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler().fit(X_train)  #Compute the statistics to be used for later scaling.\n",
    "print(sc.mean_)  #mean\n",
    "print(sc.scale_) #standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.65697597,  1.07442806],\n",
       "       [-1.05620105, -0.61094929],\n",
       "       [-0.54748036, -0.89184551],\n",
       "       [ 0.13081389, -0.96206957],\n",
       "       [-0.54748036, -0.89184551]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform: (x-u)/std.\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_train_std[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaler instance can then be used on new data to transform it the same way it did on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_std = sc.transform(X_test)\n",
    "print(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also use fit_transform method (i.e., fit and then transform)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9849854   0.90732417]\n",
      " [-0.93917213  0.15502021]\n",
      " [-0.11453319  0.49697656]\n",
      " [-0.66429248 -0.9392401 ]\n",
      " [ 0.16034646 -0.9392401 ]\n",
      " [ 1.94706417  1.11249798]\n",
      " [-0.66429248 -0.80245756]\n",
      " [ 0.9849854   1.24928052]\n",
      " [ 0.43522611  1.18088925]\n",
      " [ 0.71010576  1.11249798]]\n"
     ]
    }
   ],
   "source": [
    "                      \n",
    "X_train_std = sc.fit_transform(X_train)  \n",
    "X_test_std = sc.fit_transform(X_test)\n",
    "print(X_test_std[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of X_train_std: -0.0\n",
      "std of X_train_std: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('mean of X_train_std:',np.round(X_train_std.mean(),4))\n",
    "print('std of X_train_std:',X_train_std.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normaliaztion\n",
    "    Transforms features by scaling each feature to a given range.\n",
    "    The transformation is given by:\n",
    "\n",
    "    X' = X - X.min(axis=0) / ((X.max(axis=0) - X.min(axis=0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.811288436119874\n",
      "29.54388998067847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.random.normal(50, 6, 100)  # np.random.normal(mu,sigma,size))\n",
    "y1 = np.random.normal(5, 0.5, 100)\n",
    "\n",
    "x2 = np.random.normal(30,6,100)\n",
    "y2 = np.random.normal(4,0.5,100)\n",
    "plt.scatter(x1,y1,c='b',marker='s',s=20,alpha=0.8)\n",
    "plt.scatter(x2,y2,c='r', marker='^', s=20, alpha=0.8)\n",
    "\n",
    "print(np.sum(x1)/len(x1))\n",
    "print(np.sum(x2)/len(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.concatenate((x1,x2))\n",
    "y_val = np.concatenate((y1,y2))\n",
    "\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_norm(X):\n",
    "    return (X - X.min(axis=0)) / ((X.max(axis=0) - X.min(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52944612, 1.        , 0.9320096 , 0.49762829, 0.17022571,\n",
       "       0.07915751, 0.30656436, 0.        , 0.39614361, 0.32586789])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_norm(x_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65.7386708]\n",
      "[[0.68028007]\n",
      " [0.83016103]\n",
      " [0.80850471]\n",
      " [0.67014544]\n",
      " [0.56586107]\n",
      " [0.536854  ]\n",
      " [0.6092877 ]\n",
      " [0.51164073]\n",
      " [0.63782051]\n",
      " [0.61543627]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_val=x_val.reshape(-1, 1)\n",
    "scaler = MinMaxScaler().fit(x_val)  # default range 0~1\n",
    "print(scaler.data_max_)\n",
    "print(scaler.transform(x_val)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "#sometime you may use this\n",
    "x_diff = max(x_val)-min(x_val)\n",
    "y_diff = max(y_val)-min(y_val)\n",
    "x_normalized = [(x-min(x_val))/(x_diff) for x in x_val]\n",
    "y_normalized = [(y-min(y_val))/(y_diff) for y in y_val]\n",
    "xy_normalized = zip(x_normalized,y_normalized)\n",
    "#print(x_normalized)\n",
    "#創建label\n",
    "labels = [1]*200+[2]*200\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Ordinal features (or label)\n",
    "## Encoding Categorical features (or label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blood</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB</td>\n",
       "      <td>high</td>\n",
       "      <td>-1196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>mid</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>mid</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  blood     Y       Z\n",
       "0     A  high     NaN\n",
       "1     B   low     NaN\n",
       "2    AB  high -1196.0\n",
       "3     O   mid    72.0\n",
       "4     B   mid    83.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'blood':['A','B','AB','O','B'], \n",
    "                   'Y':['high','low','high','mid','mid'],\n",
    "                   'Z':[np.nan,np.nan,-1196,72,83]});\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(df ['blood'])\n",
    "print(encoded_Y)\n",
    "df['blood']=encoded_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blood</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "      <td>-1196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mid</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>mid</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blood     Y       Z\n",
       "0      0  high     NaN\n",
       "1      2   low     NaN\n",
       "2      1  high -1196.0\n",
       "3      3   mid    72.0\n",
       "4      2   mid    83.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-8fa60baced4b>\", line 1, in <module>\n",
      "    from keras.utils import np_utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 28, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 73, in <module>\n",
      "    from tensorflow.python.ops.standard_ops import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\standard_ops.py\", line 25, in <module>\n",
      "    from tensorflow.python import autograph\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 35, in <module>\n",
      "    from tensorflow.python.autograph import operators\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import ConversionOptions\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 71, in <module>\n",
      "    from tensorflow.python.autograph.pyct import cfg\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\cfg.py\", line 41, in <module>\n",
      "    from tensorflow.python.autograph.pyct import compiler\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\compiler.py\", line 36, in <module>\n",
      "    from tensorflow.python.autograph.pyct import origin_info\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\origin_info.py\", line 31, in <module>\n",
      "    from tensorflow.python.autograph.pyct import pretty_printer\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\pretty_printer.py\", line 24, in <module>\n",
      "    import termcolor\n",
      "ModuleNotFoundError: No module named 'termcolor'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow._api.v1 import autograph\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v1\\autograph\\__init__.py\", line 22, in <module>\n",
      "    from tensorflow._api.v1.autograph import experimental\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v1\\autograph\\experimental\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import Feature\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 71, in <module>\n",
      "    from tensorflow.python.autograph.pyct import cfg\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\cfg.py\", line 41, in <module>\n",
      "    from tensorflow.python.autograph.pyct import compiler\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\compiler.py\", line 36, in <module>\n",
      "    from tensorflow.python.autograph.pyct import origin_info\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\origin_info.py\", line 31, in <module>\n",
      "    from tensorflow.python.autograph.pyct import pretty_printer\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\pretty_printer.py\", line 24, in <module>\n",
      "    import termcolor\n",
      "ModuleNotFoundError: No module named 'termcolor'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-8fa60baced4b>\", line 1, in <module>\n",
      "    from keras.utils import np_utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 28, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 73, in <module>\n",
      "    from tensorflow.python.ops.standard_ops import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\standard_ops.py\", line 25, in <module>\n",
      "    from tensorflow.python import autograph\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 35, in <module>\n",
      "    from tensorflow.python.autograph import operators\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import ConversionOptions\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 71, in <module>\n",
      "    from tensorflow.python.autograph.pyct import cfg\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\cfg.py\", line 41, in <module>\n",
      "    from tensorflow.python.autograph.pyct import compiler\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\compiler.py\", line 36, in <module>\n",
      "    from tensorflow.python.autograph.pyct import origin_info\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\origin_info.py\", line 31, in <module>\n",
      "    from tensorflow.python.autograph.pyct import pretty_printer\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\pretty_printer.py\", line 24, in <module>\n",
      "    import termcolor\n",
      "ModuleNotFoundError: No module named 'termcolor'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow._api.v1 import autograph\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v1\\autograph\\__init__.py\", line 22, in <module>\n",
      "    from tensorflow._api.v1.autograph import experimental\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v1\\autograph\\experimental\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import Feature\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 71, in <module>\n",
      "    from tensorflow.python.autograph.pyct import cfg\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\cfg.py\", line 41, in <module>\n",
      "    from tensorflow.python.autograph.pyct import compiler\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\compiler.py\", line 36, in <module>\n",
      "    from tensorflow.python.autograph.pyct import origin_info\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\origin_info.py\", line 31, in <module>\n",
      "    from tensorflow.python.autograph.pyct import pretty_printer\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\pretty_printer.py\", line 24, in <module>\n",
      "    import termcolor\n",
      "ModuleNotFoundError: No module named 'termcolor'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-8fa60baced4b>\", line 1, in <module>\n",
      "    from keras.utils import np_utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 28, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 73, in <module>\n",
      "    from tensorflow.python.ops.standard_ops import *\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\standard_ops.py\", line 25, in <module>\n",
      "    from tensorflow.python import autograph\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 35, in <module>\n",
      "    from tensorflow.python.autograph import operators\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import ConversionOptions\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 71, in <module>\n",
      "    from tensorflow.python.autograph.pyct import cfg\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\cfg.py\", line 41, in <module>\n",
      "    from tensorflow.python.autograph.pyct import compiler\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\compiler.py\", line 36, in <module>\n",
      "    from tensorflow.python.autograph.pyct import origin_info\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\origin_info.py\", line 31, in <module>\n",
      "    from tensorflow.python.autograph.pyct import pretty_printer\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\pretty_printer.py\", line 24, in <module>\n",
      "    import termcolor\n",
      "ModuleNotFoundError: No module named 'termcolor'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3434, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3356, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow._api.v1 import autograph\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v1\\autograph\\__init__.py\", line 22, in <module>\n",
      "    from tensorflow._api.v1.autograph import experimental\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v1\\autograph\\experimental\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.autograph.core.converter import Feature\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\core\\converter.py\", line 71, in <module>\n",
      "    from tensorflow.python.autograph.pyct import cfg\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\cfg.py\", line 41, in <module>\n",
      "    from tensorflow.python.autograph.pyct import compiler\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\compiler.py\", line 36, in <module>\n",
      "    from tensorflow.python.autograph.pyct import origin_info\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\origin_info.py\", line 31, in <module>\n",
      "    from tensorflow.python.autograph.pyct import pretty_printer\n",
      "  File \"C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\pyct\\pretty_printer.py\", line 24, in <module>\n",
      "    import termcolor\n",
      "ModuleNotFoundError: No module named 'termcolor'\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "# convert integers to one hot encoding\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)  # one-hot encoding [0. 1. 0.] \n",
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
